{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_ADDRESS = 'lhl-data-bootcamp.crzjul5qln0e.ca-central-1.rds.amazonaws.com' \n",
    "POSTGRES_PORT = '5432' \n",
    "POSTGRES_USERNAME = 'lhl_student' \n",
    "POSTGRES_PASSWORD = 'lhl_student' \n",
    "POSTGRES_DBNAME='mid_term_project'\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, \n",
    "                                                                                        password=POSTGRES_PASSWORD, \n",
    "                                                                                        ipaddress=POSTGRES_ADDRESS, \n",
    "                                                                                        port=POSTGRES_PORT, \n",
    "                                                                                        dbname=POSTGRES_DBNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight=pd.read_sql_query('''SELECT * FROM flights ORDER BY RANDOM() LIMIT 10000;''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>first_dep_time</th>\n",
       "      <th>total_add_gtime</th>\n",
       "      <th>longest_add_gtime</th>\n",
       "      <th>no_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>774</td>\n",
       "      <td>UA</td>\n",
       "      <td>N459UA</td>\n",
       "      <td>774</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>2165</td>\n",
       "      <td>UA</td>\n",
       "      <td>N12754</td>\n",
       "      <td>2165</td>\n",
       "      <td>10721</td>\n",
       "      <td>BOS</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>1439</td>\n",
       "      <td>AA</td>\n",
       "      <td>N940AN</td>\n",
       "      <td>1439</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>...</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>4279</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7725A</td>\n",
       "      <td>4279</td>\n",
       "      <td>14869</td>\n",
       "      <td>SLC</td>\n",
       "      <td>...</td>\n",
       "      <td>590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>2066</td>\n",
       "      <td>AA</td>\n",
       "      <td>N916US</td>\n",
       "      <td>2066</td>\n",
       "      <td>14100</td>\n",
       "      <td>PHL</td>\n",
       "      <td>...</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0  2019-05-31                 UA                 UA          UA   \n",
       "1  2019-06-10                 UA                 UA          UA   \n",
       "2  2018-08-17                 AA                 AA          AA   \n",
       "3  2018-09-15                 WN                 WN          WN   \n",
       "4  2019-06-04                 AA                 AA          AA   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                 774                UA   N459UA                774   \n",
       "1                2165                UA   N12754               2165   \n",
       "2                1439                AA   N940AN               1439   \n",
       "3                4279                WN   N7725A               4279   \n",
       "4                2066                AA   N916US               2066   \n",
       "\n",
       "   origin_airport_id origin  ... distance  carrier_delay weather_delay  \\\n",
       "0              11292    DEN  ...    692.0            0.0           0.0   \n",
       "1              10721    BOS  ...    200.0            NaN           NaN   \n",
       "2              14107    PHX  ...   2133.0            NaN           NaN   \n",
       "3              14869    SLC  ...    590.0            NaN           NaN   \n",
       "4              14100    PHL  ...   2370.0            NaN           NaN   \n",
       "\n",
       "  nas_delay  security_delay  late_aircraft_delay  first_dep_time  \\\n",
       "0      36.0             0.0                  0.0            None   \n",
       "1       NaN             NaN                  NaN            None   \n",
       "2       NaN             NaN                  NaN            None   \n",
       "3       NaN             NaN                  NaN            None   \n",
       "4       NaN             NaN                  NaN            None   \n",
       "\n",
       "   total_add_gtime  longest_add_gtime  no_name  \n",
       "0              NaN                NaN     None  \n",
       "1              NaN                NaN     None  \n",
       "2              NaN                NaN     None  \n",
       "3              NaN                NaN     None  \n",
       "4              NaN                NaN     None  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight=df_flight[['fl_date', 'air_time','mkt_unique_carrier', 'branded_code_share', 'mkt_carrier','mkt_carrier_fl_num','op_unique_carrier', 'tail_num','op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name','dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time','dep_delay','crs_arr_time', 'dup', 'crs_elapsed_time','flights', 'distance','arr_delay','cancelled','diverted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date                 0\n",
       "air_time              202\n",
       "mkt_unique_carrier      0\n",
       "branded_code_share      0\n",
       "mkt_carrier             0\n",
       "mkt_carrier_fl_num      0\n",
       "op_unique_carrier       0\n",
       "tail_num               35\n",
       "op_carrier_fl_num       0\n",
       "origin_airport_id       0\n",
       "origin                  0\n",
       "origin_city_name        0\n",
       "dest_airport_id         0\n",
       "dest                    0\n",
       "dest_city_name          0\n",
       "crs_dep_time            0\n",
       "dep_delay             166\n",
       "crs_arr_time            0\n",
       "dup                     0\n",
       "crs_elapsed_time        0\n",
       "flights                 0\n",
       "distance                0\n",
       "arr_delay             201\n",
       "cancelled               0\n",
       "diverted                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight=df_flight.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date and time columns\n",
    "df_flight['fl_date'] = pd.to_datetime(df_flight['fl_date'], errors='coerce')\n",
    "df_flight['month'] = df_flight['fl_date'].dt.month\n",
    "df_flight['day_of_week'] = df_flight['fl_date'].dt.dayofweek\n",
    "df_flight['day_of_month'] = df_flight['fl_date'].dt.day\n",
    "df_flight['year'] = df_flight['fl_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns for departure and arrival hours\n",
    "df_flight['crs_dep_time'] = df_flight['crs_dep_time'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "df_flight['crs_arr_time'] = df_flight['crs_arr_time'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "df_flight['dep_hour']=df_flight['crs_dep_time'].str[:2]\n",
    "df_flight['arr_hour']=df_flight['crs_arr_time'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the months into four seasons\n",
    "df_flight['seasons']='spring'\n",
    "df_flight.loc[df_flight['month'].between(6, 8), 'seasons']= 'summer'\n",
    "df_flight.loc[df_flight['month'].between(9, 11), 'seasons']= 'autum'\n",
    "df_flight.loc[df_flight['month'].between(12, 2), 'seasons']= 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>air_time</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>year</th>\n",
       "      <th>dep_hour</th>\n",
       "      <th>arr_hour</th>\n",
       "      <th>seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>85.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>774</td>\n",
       "      <td>UA</td>\n",
       "      <td>N459UA</td>\n",
       "      <td>774</td>\n",
       "      <td>11292</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>2165</td>\n",
       "      <td>UA</td>\n",
       "      <td>N12754</td>\n",
       "      <td>2165</td>\n",
       "      <td>10721</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>261.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>1439</td>\n",
       "      <td>AA</td>\n",
       "      <td>N940AN</td>\n",
       "      <td>1439</td>\n",
       "      <td>14107</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>05</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>92.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>4279</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7725A</td>\n",
       "      <td>4279</td>\n",
       "      <td>14869</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2018</td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td>autum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>298.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>2066</td>\n",
       "      <td>AA</td>\n",
       "      <td>N916US</td>\n",
       "      <td>2066</td>\n",
       "      <td>14100</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fl_date  air_time mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0 2019-05-31      85.0                 UA                 UA          UA   \n",
       "1 2019-06-10      51.0                 UA                 UA          UA   \n",
       "2 2018-08-17     261.0                 AA                 AA          AA   \n",
       "3 2018-09-15      92.0                 WN                 WN          WN   \n",
       "4 2019-06-04     298.0                 AA                 AA          AA   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                 774                UA   N459UA                774   \n",
       "1                2165                UA   N12754               2165   \n",
       "2                1439                AA   N940AN               1439   \n",
       "3                4279                WN   N7725A               4279   \n",
       "4                2066                AA   N916US               2066   \n",
       "\n",
       "   origin_airport_id  ... arr_delay cancelled  diverted month day_of_week  \\\n",
       "0              11292  ...      36.0       0.0       0.0     5           4   \n",
       "1              10721  ...      -4.0       0.0       0.0     6           0   \n",
       "2              14107  ...      -3.0       0.0       0.0     8           4   \n",
       "3              14869  ...      -9.0       0.0       0.0     9           5   \n",
       "4              14100  ...     -38.0       0.0       0.0     6           1   \n",
       "\n",
       "  day_of_month  year dep_hour arr_hour  seasons  \n",
       "0           31  2019       11       14   spring  \n",
       "1           10  2019       08       09   summer  \n",
       "2           17  2018       21       05   summer  \n",
       "3           15  2018       08       09    autum  \n",
       "4            4  2019       18       21   summer  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the depature and arrival hours into day sections\n",
    "df_flight['dep_hour']=df_flight['dep_hour'].astype(int)\n",
    "df_flight['dep_time_during_day']='night'\n",
    "df_flight.loc[df_flight['dep_hour'].between(12,18), 'dep_time_during_day']= 'afternoon'\n",
    "df_flight.loc[df_flight['dep_hour'].between(19,23), 'dep_time_during_day']= 'evening'\n",
    "df_flight.loc[df_flight['dep_hour'].between(4,11), 'dep_time_during_day']= 'morning'\n",
    "\n",
    "df_flight['arr_hour']=df_flight['arr_hour'].astype(int)\n",
    "df_flight['arr_time_during_day']='night'\n",
    "df_flight.loc[df_flight['arr_hour'].between(12,18), 'arr_time_during_day']= 'afternoon'\n",
    "df_flight.loc[df_flight['arr_hour'].between(19,23), 'arr_time_during_day']= 'evening'\n",
    "df_flight.loc[df_flight['arr_hour'].between(4,11), 'arr_time_during_day']= 'morning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight = df_flight.drop('fl_date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "afternoon    4109\n",
       "morning      4032\n",
       "evening      1622\n",
       "night          31\n",
       "Name: dep_time_during_day, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight['dep_time_during_day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Short     8522\n",
       "Medium    1235\n",
       "Long        32\n",
       "Name: flight_duration_type, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to air_time and arr_delay to category\n",
    "def flight_duration(x):\n",
    "    if x <=180:\n",
    "        return 'Short'\n",
    "    elif x >180 and x<360:\n",
    "        return 'Medium'\n",
    "    elif x>360:\n",
    "        return 'Long'\n",
    "\n",
    "df_flight['flight_duration_type']=df_flight['air_time'].apply(lambda x: flight_duration(x))\n",
    "df_flight['flight_duration_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating State name from city\n",
    "df_flight['origin_state']=df_flight['origin_city_name'].apply(lambda x: x.split(', ')[1])\n",
    "df_flight['destination_state']=df_flight['dest_city_name'].apply(lambda x: x.split(', ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the mean of departure and arrival delays based on different carriers\n",
    "df_flight['dep_delay_mean_by_carrier']=df_flight.groupby(['op_unique_carrier'])['dep_delay'].transform(np.mean)\n",
    "df_flight['arr_delay_mean_by_carrier']=df_flight.groupby(['op_unique_carrier'])['arr_delay'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode arrival delay\n",
    "df_flight['arr_delay_cat'] = df_flight['arr_delay'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# ENCODE AIRPORTS AND TAILNUM\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "df_flight['mkt_carrier'] = encoder.fit_transform(df_flight[['mkt_carrier']])\n",
    "df_flight['mkt_unique_carrier'] = encoder.fit_transform(df_flight[['mkt_unique_carrier']])\n",
    "df_flight['mkt_carrier_fl_num'] = encoder.fit_transform(df_flight[['mkt_carrier_fl_num']])\n",
    "df_flight['op_unique_carrier'] = encoder.fit_transform(df_flight[['op_unique_carrier']])\n",
    "df_flight['tail_num'] = encoder.fit_transform(df_flight[['tail_num']])\n",
    "df_flight['op_carrier_fl_num'] = encoder.fit_transform(df_flight[['op_carrier_fl_num']])\n",
    "df_flight['origin_airport_id'] = encoder.fit_transform(df_flight[['origin_airport_id']])\n",
    "df_flight['dest_airport_id'] = encoder.fit_transform(df_flight[['dest_airport_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the air traffics based on the airports\n",
    "df_flight['origin_airport_taffic']=df_flight.groupby(['origin_airport_id'])['flights'].transform(np.sum)\n",
    "df_flight['dest_airport_traffic']=df_flight.groupby(['dest_airport_id'])['flights'].transform(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data by getting dummies\n",
    "dummy_durtypes=pd.get_dummies(df_flight[['flight_duration_type', 'dep_time_during_day', 'arr_time_during_day', 'seasons']])\n",
    "\n",
    "df_flight=pd.concat([df_flight, dummy_durtypes], axis=1).drop(['flight_duration_type', 'dep_time_during_day', 'arr_time_during_day', 'seasons'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_time                         0\n",
       "mkt_unique_carrier               0\n",
       "branded_code_share               0\n",
       "mkt_carrier                      0\n",
       "mkt_carrier_fl_num               0\n",
       "op_unique_carrier                0\n",
       "tail_num                         0\n",
       "op_carrier_fl_num                0\n",
       "origin_airport_id                0\n",
       "origin                           0\n",
       "origin_city_name                 0\n",
       "dest_airport_id                  0\n",
       "dest                             0\n",
       "dest_city_name                   0\n",
       "crs_dep_time                     0\n",
       "dep_delay                        0\n",
       "crs_arr_time                     0\n",
       "dup                              0\n",
       "crs_elapsed_time                 0\n",
       "flights                          0\n",
       "distance                         0\n",
       "arr_delay                        0\n",
       "cancelled                        0\n",
       "diverted                         0\n",
       "month                            0\n",
       "day_of_week                      0\n",
       "day_of_month                     0\n",
       "year                             0\n",
       "dep_hour                         0\n",
       "arr_hour                         0\n",
       "origin_state                     0\n",
       "destination_state                0\n",
       "dep_delay_mean_by_carrier        0\n",
       "arr_delay_mean_by_carrier        0\n",
       "arr_delay_cat                    0\n",
       "origin_airport_taffic            0\n",
       "dest_airport_traffic             0\n",
       "flight_duration_type_Long        0\n",
       "flight_duration_type_Medium      0\n",
       "flight_duration_type_Short       0\n",
       "dep_time_during_day_afternoon    0\n",
       "dep_time_during_day_evening      0\n",
       "dep_time_during_day_morning      0\n",
       "dep_time_during_day_night        0\n",
       "arr_time_during_day_afternoon    0\n",
       "arr_time_during_day_evening      0\n",
       "arr_time_during_day_morning      0\n",
       "arr_time_during_day_night        0\n",
       "seasons_autum                    0\n",
       "seasons_spring                   0\n",
       "seasons_summer                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight=df_flight.drop(['dep_delay','mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
    "                            'mkt_carrier_fl_num', 'op_unique_carrier','op_carrier_fl_num', \n",
    "                            'origin', 'origin_city_name','dup','dest','dest_city_name',\n",
    "                            'origin_state', 'destination_state', \n",
    "                            'cancelled','diverted',\n",
    "                           ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_time</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_time_during_day_evening</th>\n",
       "      <th>dep_time_during_day_morning</th>\n",
       "      <th>dep_time_during_day_night</th>\n",
       "      <th>arr_time_during_day_afternoon</th>\n",
       "      <th>arr_time_during_day_evening</th>\n",
       "      <th>arr_time_during_day_morning</th>\n",
       "      <th>arr_time_during_day_night</th>\n",
       "      <th>seasons_autum</th>\n",
       "      <th>seasons_spring</th>\n",
       "      <th>seasons_summer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>1403</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0800</td>\n",
       "      <td>0918</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261.0</td>\n",
       "      <td>4188.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2155</td>\n",
       "      <td>0533</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.0</td>\n",
       "      <td>2934.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0805</td>\n",
       "      <td>0900</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.0</td>\n",
       "      <td>3967.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1833</td>\n",
       "      <td>2132</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_time  tail_num  origin_airport_id  dest_airport_id crs_dep_time  \\\n",
       "0      85.0    1634.0               77.0             56.0         1115   \n",
       "1      51.0     199.0               39.0             99.0         0800   \n",
       "2     261.0    4188.0              231.0             99.0         2155   \n",
       "3      92.0    2934.0              282.0            160.0         0805   \n",
       "4     298.0    3967.0              230.0            260.0         1833   \n",
       "\n",
       "  crs_arr_time  crs_elapsed_time  flights  distance  arr_delay  ...  \\\n",
       "0         1403             108.0      1.0     692.0       36.0  ...   \n",
       "1         0918              78.0      1.0     200.0       -4.0  ...   \n",
       "2         0533             278.0      1.0    2133.0       -3.0  ...   \n",
       "3         0900             115.0      1.0     590.0       -9.0  ...   \n",
       "4         2132             359.0      1.0    2370.0      -38.0  ...   \n",
       "\n",
       "   dep_time_during_day_evening  dep_time_during_day_morning  \\\n",
       "0                            0                            1   \n",
       "1                            0                            1   \n",
       "2                            1                            0   \n",
       "3                            0                            1   \n",
       "4                            0                            0   \n",
       "\n",
       "   dep_time_during_day_night  arr_time_during_day_afternoon  \\\n",
       "0                          0                              1   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   arr_time_during_day_evening  arr_time_during_day_morning  \\\n",
       "0                            0                            0   \n",
       "1                            0                            1   \n",
       "2                            0                            1   \n",
       "3                            0                            1   \n",
       "4                            1                            0   \n",
       "\n",
       "   arr_time_during_day_night  seasons_autum  seasons_spring  seasons_summer  \n",
       "0                          0              0               1               0  \n",
       "1                          0              0               0               1  \n",
       "2                          0              0               0               1  \n",
       "3                          0              1               0               0  \n",
       "4                          0              0               0               1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.decomposition import PCA\\nimport matplotlib.pyplot as plt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YET TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_flight.arr_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = np.array(df_flight.arr_delay_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_flight.drop(['arr_delay', 'arr_delay_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train Test Split and Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.70,test_size=0.30, random_state=101, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample = pd.DataFrame(X_train).sample(frac = 0.1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating y_train_cat and y_test_cat\\n\",\n",
    "X_train, X_test, y_train_cat, y_test_cat = model_selection.train_test_split(X, y_cat, train_size=0.70,test_size=0.30, random_state=101, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sample = pd.DataFrame(y_train).sample(frac = 0.1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainCat_sample = pd.DataFrame(y_train_cat).sample(frac = 0.1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sample = pd.DataFrame(X_test).sample(frac = 0.1).values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scaler = StandardScaler()\\nX = scaler.fit_transform(X)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = (y - y.mean()) / y.std()'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y = (y - y.mean()) / y.std()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('linear_model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_model', LinearRegression())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear = linear_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = linear_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027835567454822185"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_linear_pickle', 'wb') as linear_file:\n",
    "    pickle.dump(linear_pipe, linear_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_linear_pickle', 'rb') as linear_file:\n",
    "    model_linear = pickle.load(linear_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear_ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elasnet_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters ={\n",
    "    'elasnet_model__alpha': [1],\n",
    "    'elasnet_model__l1_ratio': [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasnet_model_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('elasnet_model', ElasticNet())])\n",
    "elasnet_model_grid = GridSearchCV(estimator=elasnet_model_pipe, param_grid=hyperparameters, scoring = 'r2', verbose=0, cv= 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample test to find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elasnet_model_grid.fit(X_train_sample, y_trainCat_sample.ravel())\\ny_pred_randFor_class = elasnet_model_grid.predict(X_test_sample)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''elasnet_model_grid.fit(X_train_sample, y_trainCat_sample.ravel())\n",
    "y_pred_randFor_class = elasnet_model_grid.predict(X_test_sample)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elasnet_model_grid.best_estimator_'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''elasnet_model_grid.best_estimator_'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted to Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('elasnet_model', ElasticNet())]),\n",
       "             param_grid={'elasnet_model__alpha': [1],\n",
       "                         'elasnet_model__l1_ratio': [0.0001]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet_model_grid.fit(X_train, y_train_cat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_randFor_class = elasnet_model_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('elasnet_model', ElasticNet(alpha=1, l1_ratio=0.0001))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet_model_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021238705625799104"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = elasnet_model_grid.score(X_test, y_test_cat)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polyfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_model = PolynomialFeatures()\n",
    "poly_model_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('poly_model', PolynomialFeatures(2)), ('linear_reg', LinearRegression())])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample test to find the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model_pipe.fit(X_train_sample, y_train_sample.ravel())\n",
    "y_pred_poly = poly_model_pipe.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('poly_model', PolynomialFeatures()),\n",
       "                ('linear_reg', LinearRegression())])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.5319028945327695e+27"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = poly_model_pipe.score(X_test, y_test_cat)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naives Bayes, GaussianNB Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('NB_Gauss_model', GaussianNB())])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_Gauss_model = GaussianNB()\n",
    "NB_Gauss_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('NB_Gauss_model', GaussianNB())])\n",
    "NB_Gauss_pipe.fit(X_train, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NBGauss = NB_Gauss_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6008846546444369"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = NB_Gauss_pipe.score(X_test, y_test_cat)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_Gaussian_pickle', 'wb') as Gaussian_file:\n",
    "    pickle.dump(NB_Gauss_pipe, Gaussian_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_Gaussian_pickle', 'rb') as Gaussian_file:\n",
    "    model_Gaussian = pickle.load(Gaussian_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_regression_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'rand_forrestReg__n_estimators': [1000],\n",
    "    'rand_forrestReg__max_depth': [2],\n",
    "    'rand_forrestReg__min_samples_split':[6], \n",
    "    'rand_forrestReg__bootstrap':[True],\n",
    "    'rand_forrestReg__criterion' :['mse']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_reg_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('rand_forrestReg', RandomForestRegressor())])\n",
    "forest_reg_grid = GridSearchCV(estimator=Forest_reg_pipe, param_grid=hyperparameters, scoring = 'r2', verbose=0, cv= 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample test to find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forest_reg_grid.fit(X_train_sample, y_train_sample.ravel())\\ny_pred_randFor_class = forest_reg_grid.predict(X_test_sample)'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''forest_reg_grid.fit(X_train_sample, y_train_sample.ravel())\n",
    "y_pred_randFor_class = forest_reg_grid.predict(X_test_sample)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest_reg_grid.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted to Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "c:\\Users\\benny\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "forest_reg_grid.fit(X_train, y_train)\n",
    "y_pred_randFo = forest_reg_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('rand_forrestReg',\n",
       "                 RandomForestRegressor(criterion='mse', max_depth=2,\n",
       "                                       min_samples_split=6,\n",
       "                                       n_estimators=1000))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010367720729129726"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = forest_reg_grid.score(X_test, y_test)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_Forrest_reg_pickle', 'wb') as forest_reg_file:\n",
    "    pickle.dump(forest_reg_grid, forest_reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_Forrest_reg_pickle', 'rb') as forest_reg_file:\n",
    "    model_Forrest_reg_pickle = pickle.load(forest_reg_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "model_svm_class = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'model_svm_class__kernel': ['linear'],\n",
    "                   'model_svm_class__C':[1],\n",
    "                   'model_svm_class__degree':[1]\n",
    "}\n",
    "SVC_grid_class = GridSearchCV(estimator=model_svm_class, param_grid=hyperparameters, scoring = 'r2', verbose=0, cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_class_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('model_svm_class', SVC())])\n",
    "smv_class_grid = GridSearchCV(estimator=svm_class_pipe, param_grid=hyperparameters, scoring = 'r2', verbose=0, cv= 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample test to find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model_svm_class', SVC(C=1, degree=1, kernel='linear'))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv_class_grid.fit(X_train_sample, y_trainCat_sample.ravel())\n",
    "y_pred_svm = smv_class_grid.predict(X_test_sample)\n",
    "smv_class_grid.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted to Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv_class_grid.fit(X_train,y_train_cat)\n",
    "y_pred_svc_cat = smv_class_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model_svm_class', SVC(C=1, degree=1, kernel='linear'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smv_class_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3995426030924909"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = smv_class_grid.score(X_test, y_test_cat)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_smv_class_pickle', 'wb') as smv_class_file:\n",
    "    pickle.dump(smv_class_grid, smv_class_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_smv_class_pickle', 'rb') as smv_class_file:\n",
    "    model_smv_class_pickle = pickle.load(smv_class_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\benny\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\benny\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\benny\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'xg_reg__objective' : ['reg:squarederror'],\n",
    "    'xg_reg__colsample_bytree':[0.1],\n",
    "    'xg_reg__n_estimators': [3000],\n",
    "    'xg_reg__max_depth': [4],\n",
    "    'xg_reg__learning_rate': [0.0001],\n",
    "    'xg_reg__alpha': [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_class_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('xg_reg', xgb.XGBRegressor())])\n",
    "xgb_grid = GridSearchCV(estimator=svm_class_pipe, param_grid=hyperparameters, scoring = 'r2', verbose=0, cv= 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample Test to find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid.fit(X_train_sample, y_train_sample.ravel())\n",
    "y_pred_xbg = xgb_grid.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('xg_reg',\n",
       "                 XGBRegressor(alpha=5, base_score=None, booster=None,\n",
       "                              callbacks=None, colsample_bylevel=None,\n",
       "                              colsample_bynode=None, colsample_bytree=0.1,\n",
       "                              early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None,\n",
       "                              learning_rate=0.0001, max_bin=None,\n",
       "                              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=3000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, ...))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted to Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid.fit(X_train,y_train)\n",
    "y_pred_xbg = xgb_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('xg_reg',\n",
       "                 XGBRegressor(alpha=5, base_score=None, booster=None,\n",
       "                              callbacks=None, colsample_bylevel=None,\n",
       "                              colsample_bynode=None, colsample_bytree=0.1,\n",
       "                              early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None,\n",
       "                              learning_rate=0.0001, max_bin=None,\n",
       "                              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=3000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, ...))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00041851692761607495"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = xgb_grid.score(X_test, y_test)\n",
    "r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_xgb_grid_pickle', 'wb') as xgb_reg_file:\n",
    "    pickle.dump(xgb_grid, xgb_reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_xgb_grid_pickle', 'rb') as xgb_reg_file:\n",
    "    model_xgb_grid_pickle = pickle.load(xgb_reg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "afa4bd7b3b17809ce727499f5d6be9ee5d785b25a447050def9a3445025e331f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
